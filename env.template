# =============================================================================
# Apofasi Backend - Environment Variables Template
# =============================================================================
# Copy this file to .env and fill in your actual API keys
# On Windows: copy env.template .env
# On Linux/Mac: cp env.template .env

# =============================================================================
# Neo4j Database Configuration
# =============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j

# =============================================================================
# LLM API Keys
# =============================================================================

# Google Gemini API (for query understanding and semantic segmentation)
# Get your API key from: https://ai.google.dev/
GOOGLE_API_KEY=your_gemini_api_key_here

# Groq Cloud API (for fast inference)
# Get your API key from: https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here

# Together AI API (for open-source models)
# Get your API key from: https://api.together.xyz/
TOGETHER_API_KEY=your_together_api_key_here
TOGETHER_API_BASE_URL=https://api.together.xyz/v1

# Hugging Face API (for models and inference)
# Get your API key from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_API_BASE_URL=https://api-inference.huggingface.co

# WaveSpeed API (for inference)
# Get your API key from: https://wavespeed.ai/
WAVESPEED_API_KEY=your_wavespeed_api_key_here
WAVESPEED_API_BASE_URL=https://api.wavespeed.ai/v1

# =============================================================================
# Optional: Model Selection
# =============================================================================
# Uncomment and set to override default models

# Default LLM for query understanding (options: gemini, groq, together, huggingface)
# DEFAULT_LLM_PROVIDER=gemini

# Default embedding model (options: nomic, huggingface)
# DEFAULT_EMBEDDING_PROVIDER=nomic

# =============================================================================
# Optional: Rate Limiting & Retry Configuration
# =============================================================================
# MAX_RETRIES=3
# RETRY_DELAY_SECONDS=5
# RATE_LIMIT_REQUESTS_PER_MINUTE=60
